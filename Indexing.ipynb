{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f06242-3673-4676-a346-c498838974cc",
   "metadata": {},
   "source": [
    "# Indexing the pdf file into chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8467c-7a40-4b5a-a948-541c53ff478f",
   "metadata": {},
   "source": [
    "Docling Library Ref: https://docling-project.github.io/docling/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbf2f38-0508-405d-96ed-24ff88b24bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import ast\n",
    "import openai\n",
    "import base64\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from docling.chunking import HybridChunker\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling_core.types.doc import PictureItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7ccb00-8cd8-4f80-83c6-593568b39250",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFile = \"./datasets/Dataset1.pdf\"\n",
    "mdFile = \"./datasets/Dataset1.md\"\n",
    "embFile = \"./data/largeEmbeddings.csv\"\n",
    "chunksOutFile = \"./data/chunksDocling.txt\"\n",
    "\n",
    "imageDir = \"./images/\"\n",
    "\n",
    "embedModelName = \"BAAI/bge-large-en-v1.5\"\n",
    "embedModel = SentenceTransformer(embedModelName)\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"rag\"]\n",
    "collection = db[\"doc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a06d6-48a2-4b0b-8625-b87bbf53dc49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Builiding a .md File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c665f2-fcce-4638-b7eb-4ac7313e6368",
   "metadata": {},
   "source": [
    "Convert from pdf to docling format if not already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78f3371-485f-4d26-a53e-b66f8dd3cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(embFile):\n",
    "    source = pdfFile\n",
    "    \n",
    "    # Docling Convertor\n",
    "    # Pass in options to include images\n",
    "    opts = PdfPipelineOptions()\n",
    "    opts.generate_picture_images = True\n",
    "\n",
    "    converter = DocumentConverter(\n",
    "        format_options = {InputFormat.PDF: PdfFormatOption(pipeline_options=opts)}\n",
    "    )\n",
    "    result = converter.convert(source)\n",
    "\n",
    "    # Convert and write pdf contents to .md File\n",
    "    result_markdown = result.document.export_to_markdown()\n",
    "\n",
    "    with open(mdFile, 'w', encoding='utf-8') as f:\n",
    "        f.write(result_markdown)\n",
    "\n",
    "    print(f\"Markdown written to: {mdFile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048062c-77bf-45cf-8b56-5de6b5329779",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text and Table Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b084a39-36d3-475d-934a-21d14b6ec9c7",
   "metadata": {},
   "source": [
    "Uses the docling library's chunker to convert the pdf into chunks. Also converts tables into text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42e2610-61d4-4d78-9fe7-5ee06a345e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(embFile):\n",
    "    chunker = HybridChunker()\n",
    "    chunk_iter = chunker.chunk(dl_doc=result.document)\n",
    "    # Stores a list of all chunks\n",
    "    chunkL = list(chunk_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa51ae-ff7c-4e95-bc9c-0e87150d1068",
   "metadata": {},
   "source": [
    "Store chunks in .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f223bf6-83b5-406f-9830-686d0b642235",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(embFile):\n",
    "    dfL = []\n",
    "    txtChunk = \"\"\n",
    "    \n",
    "    for idx, chunk in enumerate(chunkL):\n",
    "        # Text to write in the chunks.txt file\n",
    "        txtChunk += f\"-- Chunk {idx} --\\n{chunk.text}\\n\\n\"\n",
    "\n",
    "        # Rows to create dataframe\n",
    "        row = {\n",
    "            \"Chunks\" : chunk.text,\n",
    "            \"PageNo\": chunk.model_dump()[\"meta\"][\"doc_items\"][0][\"prov\"][0][\"page_no\"]\n",
    "        }\n",
    "        dfL.append(row)\n",
    "\n",
    "\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    output_file = os.path.join(\"data\", \"chunksDocling.txt\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(txtChunk)\n",
    "\n",
    "    df = pd.DataFrame(dfL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606cd18-3539-4c34-9cdd-45b7d89ea69b",
   "metadata": {},
   "source": [
    "## Image Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40dd4a53-afd0-456f-8712-6343f27e9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_output_folder(output_folder):\n",
    "    if os.path.exists(output_folder):\n",
    "        for filename in os.listdir(output_folder):\n",
    "            file_path = os.path.join(output_folder, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    else:\n",
    "        os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927720cc-bb0d-4848-b031-f1d9f78b1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(embFile):\n",
    "    output_dir = Path(imageDir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    clear_output_folder(imageDir)\n",
    "\n",
    "    # Set to store unique hashes so that only unique images are stored\n",
    "    seen_hashes = set()\n",
    "    # Map filepath to page number\n",
    "    image_metadata = []\n",
    "\n",
    "    for idx, picture in enumerate(result.document.pictures):\n",
    "        image_ref = picture.image\n",
    "        if image_ref and image_ref.pil_image:\n",
    "            pil_image = image_ref.pil_image\n",
    "\n",
    "            # Convert image to bytes and compute hash\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            pil_image.save(img_byte_arr, format='PNG')\n",
    "            img_bytes = img_byte_arr.getvalue()\n",
    "            img_hash = hashlib.sha256(img_bytes).hexdigest()\n",
    "\n",
    "            # Save image if it's unique\n",
    "            if img_hash not in seen_hashes:\n",
    "                seen_hashes.add(img_hash)\n",
    "\n",
    "                # Determine the page number\n",
    "                page_number = -1\n",
    "                if picture.prov and picture.prov[0].page_no is not None:\n",
    "                    page_number = picture.prov[0].page_no\n",
    "\n",
    "                image_filename = f\"page-{page_number}_img{len(seen_hashes)}.png\"\n",
    "                image_path = output_dir / image_filename\n",
    "                pil_image.save(image_path)\n",
    "                \n",
    "                # Append metadata\n",
    "                image_metadata.append({\n",
    "                    'imagePath': str(image_path),\n",
    "                    'PageNo': page_number\n",
    "                })\n",
    "\n",
    "    # Store image paths and pageNo in DF\n",
    "    imgDF = pd.DataFrame(image_metadata)\n",
    "    \n",
    "    display(imgDF.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf251a-cc6c-491e-a4a2-feb3d55b1cde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get LLM generated summary of Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64edfcfd-5289-4485-87b8-56d25771083e",
   "metadata": {},
   "source": [
    "Uses GPT-4o, requires OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdcbe14a-bc43-4539-84a5-5811a6b1d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImgSummary(imgPath):\n",
    "    if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "        return \"\"\n",
    "    \n",
    "    with open(imgPath, \"rb\") as img_file:\n",
    "        image_bytes = img_file.read()\n",
    "        # Base64 Encoded image to send to LLM\n",
    "        image = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "    # Prompt and message structure\n",
    "    prompt_template = \"\"\"Describe the image in detail. Be specific about diagrams, flowchards, graphs, etc.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_template},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call the GPT-4o model\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732da8c3-3945-404d-b886-33c8bffe4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(embFile):\n",
    "    # Compute summary for each image\n",
    "    imgDF[\"Chunks\"] = imgDF[\"imagePath\"].apply(getImgSummary)\n",
    "    \n",
    "    display(imgDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec5c74-f9de-4ce5-b13a-557086e47de3",
   "metadata": {},
   "source": [
    "## Combine Image and Text Chunks in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e866db-5105-44be-b3f3-4fdc665dac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(embFile):\n",
    "    dfComb = pd.concat([df, imgDF], ignore_index=True)\n",
    "    \n",
    "    display(dfComb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2275ee-3cc0-4a7c-a07d-66e4f78b9342",
   "metadata": {},
   "source": [
    "## Compute embeddings and store chunks in mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ef9fc0-2318-46ad-8b4e-1cd71fdacfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Chunks</th>\n",
       "      <th>PageNo</th>\n",
       "      <th>imagePath</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>An Roinn Airgeadais Department of Finance\\nTra...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.014186208136379719, -0.013681311160326004, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PUBLIC WORKS CONTRACTS - CONTRACTORS</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.018307723104953766, -0.004139376804232597,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This training manual is both the course materi...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.02164776809513569, -0.022553179413080215, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1., 1 = COURSE AGENDA. 1., 2 = COURSE AGENDA. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.035058051347732544, 0.0017086670268326998, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>= 5.5. , 2 = Comparison of Risk Allocation Und...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0200276467949152, -0.00019992324814666063, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>561</td>\n",
       "      <td>Sure, please upload the image or provide detai...</td>\n",
       "      <td>77</td>\n",
       "      <td>images\\page-77_img16.png</td>\n",
       "      <td>[0.005667939316481352, -0.04764747992157936, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>562</td>\n",
       "      <td>The image shows a horizontal yellow line with ...</td>\n",
       "      <td>203</td>\n",
       "      <td>images\\page-203_img17.png</td>\n",
       "      <td>[-0.007596821524202824, 0.005338060203939676, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>563</td>\n",
       "      <td>The image contains a pie chart with four segme...</td>\n",
       "      <td>222</td>\n",
       "      <td>images\\page-222_img18.png</td>\n",
       "      <td>[0.01627928577363491, -0.012685469351708889, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>564</td>\n",
       "      <td>The image appears to be a text excerpt highlig...</td>\n",
       "      <td>226</td>\n",
       "      <td>images\\page-226_img19.png</td>\n",
       "      <td>[-0.0030819198582321405, 0.00860358402132988, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>565</td>\n",
       "      <td>Please upload the image you'd like me to descr...</td>\n",
       "      <td>242</td>\n",
       "      <td>images\\page-242_img20.png</td>\n",
       "      <td>[0.01990351267158985, -0.03579447790980339, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>566 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             Chunks  PageNo  \\\n",
       "0             0  An Roinn Airgeadais Department of Finance\\nTra...       1   \n",
       "1             1               PUBLIC WORKS CONTRACTS - CONTRACTORS       1   \n",
       "2             2  This training manual is both the course materi...       2   \n",
       "3             3  1., 1 = COURSE AGENDA. 1., 2 = COURSE AGENDA. ...       3   \n",
       "4             4  = 5.5. , 2 = Comparison of Risk Allocation Und...       3   \n",
       "..          ...                                                ...     ...   \n",
       "561         561  Sure, please upload the image or provide detai...      77   \n",
       "562         562  The image shows a horizontal yellow line with ...     203   \n",
       "563         563  The image contains a pie chart with four segme...     222   \n",
       "564         564  The image appears to be a text excerpt highlig...     226   \n",
       "565         565  Please upload the image you'd like me to descr...     242   \n",
       "\n",
       "                     imagePath  \\\n",
       "0                          NaN   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4                          NaN   \n",
       "..                         ...   \n",
       "561   images\\page-77_img16.png   \n",
       "562  images\\page-203_img17.png   \n",
       "563  images\\page-222_img18.png   \n",
       "564  images\\page-226_img19.png   \n",
       "565  images\\page-242_img20.png   \n",
       "\n",
       "                                            embeddings  \n",
       "0    [0.014186208136379719, -0.013681311160326004, ...  \n",
       "1    [-0.018307723104953766, -0.004139376804232597,...  \n",
       "2    [-0.02164776809513569, -0.022553179413080215, ...  \n",
       "3    [0.035058051347732544, 0.0017086670268326998, ...  \n",
       "4    [0.0200276467949152, -0.00019992324814666063, ...  \n",
       "..                                                 ...  \n",
       "561  [0.005667939316481352, -0.04764747992157936, -...  \n",
       "562  [-0.007596821524202824, 0.005338060203939676, ...  \n",
       "563  [0.01627928577363491, -0.012685469351708889, -...  \n",
       "564  [-0.0030819198582321405, 0.00860358402132988, ...  \n",
       "565  [0.01990351267158985, -0.03579447790980339, 0....  \n",
       "\n",
       "[566 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(embFile):\n",
    "    # Compute embeddings of each chunk\n",
    "    embeddings = embedModel.encode(dfComb[\"Chunks\"].tolist(), normalize_embeddings=True)\n",
    "    \n",
    "    dfComb[\"embeddings\"] = embeddings.tolist()\n",
    "    # Write to .csv so doesnt have to be calculated again\n",
    "    dfComb.to_csv(embFile)\n",
    "    \n",
    "    docs = dfComb.to_dict(orient=\"records\")\n",
    "\n",
    "    # Refresh mongoDB and write whole DataFrame to monogoDB\n",
    "    collection.delete_many({})\n",
    "    collection.insert_many(docs)\n",
    "    print(\"Inserted\")\n",
    "    \n",
    "else:\n",
    "    # If embeddings.csv file already exists load from .csv file\n",
    "    dfComb = pd.read_csv(embFile)\n",
    "    dfComb[\"embeddings\"] = dfComb[\"embeddings\"].apply(ast.literal_eval)\n",
    "    \n",
    "dfComb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ad00a-c658-4634-b8c4-84081a30ddf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
